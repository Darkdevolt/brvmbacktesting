import streamlit as st
import pandas as pd
import numpy as np
from scipy.stats import norm, jarque_bera, shapiro, kstest, anderson
import matplotlib.pyplot as plt
import statsmodels.api as sm

# Configuration de la page Streamlit
st.set_page_config(layout="wide", page_title="Calculateur de VaR Gaussienne")

st.title("üìà Calculateur de VaR Gaussienne")
st.markdown("""
Bienvenue dans cet outil de calcul de la Valeur √† Risque (VaR) Gaussienne.
Chargez votre fichier CSV, s√©lectionnez les colonnes appropri√©es, puis suivez les √©tapes
pour analyser vos donn√©es de rendement et estimer la VaR.
""")

# --- √âtape 1 : Collecte des donn√©es de rendements ---
st.header("√âtape 1 : Collecte et s√©lection des donn√©es")
uploaded_file = st.file_uploader("Chargez votre fichier CSV de donn√©es historiques", type="csv")

# Initialiser les variables pour les noms de colonnes dans session_state si elles n'existent pas
if 'date_column_name' not in st.session_state:
    st.session_state.date_column_name = None
if 'close_column_name' not in st.session_state:
    st.session_state.close_column_name = None
if 'columns_validated' not in st.session_state:
    st.session_state.columns_validated = False
if 'data_processed' not in st.session_state:
    st.session_state.data_processed = None # Pour stocker les donn√©es trait√©es

if uploaded_file is not None:
    try:
        data_initial = pd.read_csv(uploaded_file)
        st.success("Fichier charg√© avec succ√®s !")
        st.write("Aper√ßu des premi√®res lignes du fichier charg√© :")
        st.write(data_initial.head())

        available_columns = data_initial.columns.tolist()

        st.subheader("S√©lectionnez les colonnes √† utiliser :")

        # Logique pour pr√©-s√©lectionner si les noms communs existent
        default_date_index = 0
        if 'Date' in available_columns:
            default_date_index = available_columns.index('Date')
        elif 'date' in available_columns: # common alternative
            default_date_index = available_columns.index('date')

        # Filtre les colonnes disponibles pour 'Close' pour ne pas inclure la colonne d√©j√† s√©lectionn√©e pour la date (si elle a √©t√© choisie)
        # Cela sera mis √† jour dynamiquement si Streamlit le permet facilement, sinon on pr√©-s√©lectionne.
        # Pour la simplicit√© de ce script, on ne fait pas de mise √† jour dynamique complexe ici.

        default_close_index = 0
        potential_close_columns = [col for col in available_columns] # On ne filtre pas encore dynamiquement
        if 'Close' in potential_close_columns:
            default_close_index = potential_close_columns.index('Close')
        elif 'close' in potential_close_columns:
            default_close_index = potential_close_columns.index('close')
        elif 'Adj Close' in potential_close_columns: # common alternative
            default_close_index = potential_close_columns.index('Adj Close')


        col_select1, col_select2 = st.columns(2)
        with col_select1:
            selected_date_col = st.selectbox(
                "S√©lectionnez la colonne contenant les DATES :",
                options=available_columns,
                index=default_date_index,
                key="sb_date_col"
            )
        with col_select2:
            selected_close_col = st.selectbox(
                "S√©lectionnez la colonne contenant les prix de CL√îTURE :",
                options=[col for col in available_columns if col != selected_date_col], # √âvite de s√©lectionner la m√™me colonne
                index=([col for col in available_columns if col != selected_date_col].index('Close')
                       if 'Close' in [col for col in available_columns if col != selected_date_col]
                       else 0), # Tente de trouver 'Close' parmi les options restantes
                key="sb_close_col"
            )

        if st.button("Valider la s√©lection des colonnes et traiter les donn√©es", key="validate_cols_button"):
            if selected_date_col == selected_close_col:
                st.error("La colonne des dates et la colonne des prix de cl√¥ture doivent √™tre diff√©rentes.")
                st.session_state.columns_validated = False
            else:
                st.session_state.date_column_name = selected_date_col
                st.session_state.close_column_name = selected_close_col
                st.session_state.columns_validated = True

                # Traitement des donn√©es apr√®s validation
                data = data_initial.copy() # Travailler sur une copie
                try:
                    # Convertir la colonne 'Date' en datetime
                    data['Date_Processed'] = pd.to_datetime(data[st.session_state.date_column_name])
                    data = data.sort_values(by='Date_Processed')
                    data.set_index('Date_Processed', inplace=True)
                except Exception as e:
                    st.error(f"Erreur lors de la conversion de la colonne '{st.session_state.date_column_name}' en date. Assurez-vous qu'elle est dans un format de date valide. Erreur: {e}")
                    st.session_state.columns_validated = False # Invalider si erreur
                    st.stop()

                # S'assurer que la colonne 'Close' est num√©rique
                if not pd.api.types.is_numeric_dtype(data[st.session_state.close_column_name]):
                    try:
                        # Tenter une conversion, en avertissant l'utilisateur
                        data[st.session_state.close_column_name] = pd.to_numeric(data[st.session_state.close_column_name], errors='coerce')
                        if data[st.session_state.close_column_name].isnull().any():
                            st.warning(f"Des valeurs non num√©riques dans la colonne '{st.session_state.close_column_name}' ont √©t√© converties en NaN apr√®s une tentative de conversion.")
                    except Exception as e:
                        st.error(f"La colonne '{st.session_state.close_column_name}' doit √™tre de type num√©rique. Tentative de conversion √©chou√©e. Erreur: {e}")
                        st.session_state.columns_validated = False # Invalider si erreur
                        st.stop()

                data.dropna(subset=[st.session_state.close_column_name], inplace=True) # Supprimer les lignes o√π le close est NaN apr√®s conversion

                # Calcul des rendements
                data['Rendements'] = np.log(data[st.session_state.close_column_name] / data[st.session_state.close_column_name].shift(1))
                data.dropna(subset=['Rendements'], inplace=True) # Supprimer la premi√®re ligne NaN due au calcul du rendement

                st.session_state.data_processed = data # Stocker les donn√©es trait√©es

                st.success(f"Colonnes valid√©es : Date='{st.session_state.date_column_name}', Cl√¥ture='{st.session_state.close_column_name}'. Donn√©es pr√™tes pour l'analyse.")
                st.subheader("Aper√ßu des donn√©es de rendements calcul√©s :")
                st.write(st.session_state.data_processed[[st.session_state.close_column_name, 'Rendements']].head())

                if len(st.session_state.data_processed['Rendements']) < 250:
                    st.warning(f"Attention : Vous avez {len(st.session_state.data_processed['Rendements'])} observations de rendements. Il est recommand√© d'en avoir au moins 250.")

    except pd.errors.EmptyDataError:
        st.error("Le fichier CSV est vide.")
        st.session_state.columns_validated = False
    except ValueError as ve:
        st.error(f"Erreur de valeur dans les donn√©es du CSV. V√©rifiez le format. D√©tail: {ve}")
        st.session_state.columns_validated = False
    except Exception as e:
        st.error(f"Une erreur est survenue lors du chargement ou de la pr√©-s√©lection des colonnes : {e}")
        st.session_state.columns_validated = False

# Le reste de l'application ne s'ex√©cute que si les colonnes ont √©t√© valid√©es et les donn√©es trait√©es
if st.session_state.columns_validated and st.session_state.data_processed is not None:
    data_for_analysis = st.session_state.data_processed
    rendements = data_for_analysis['Rendements']

    # --- √âtape 2 : Analyse descriptive ---
    st.header("√âtape 2 : Analyse descriptive")
    moyenne = rendements.mean()
    ecart_type = rendements.std()
    skewness_val = rendements.skew() # Renomm√© pour √©viter conflit avec module
    kurtosis_val = rendements.kurtosis() # Kurtosis de Fisher (exc√®s), normal = 0

    st.subheader("Statistiques descriptives des rendements :")
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("Moyenne (Œº)", f"{moyenne:.6f}")
    col2.metric("√âcart-type (œÉ)", f"{ecart_type:.6f}")
    col3.metric("Skewness", f"{skewness_val:.4f}")
    col4.metric("Kurtosis (exc√®s)", f"{kurtosis_val:.4f}")

    if skewness_val != 0 or kurtosis_val > 0:
        st.warning("La skewness non nulle ou la kurtosis (exc√®s) > 0 sugg√®re une distribution potentiellement non normale.")
    else:
        st.info("La skewness et la kurtosis sont proches des valeurs attendues pour une distribution normale.")

    # --- √âtape 3 : Test de normalit√© ---
    st.header("√âtape 3 : Tests de normalit√©")
    st.markdown("Objectif : v√©rifier si les rendements suivent une loi normale.")

    alpha_test = st.slider("Seuil de significativit√© (alpha) pour les tests de normalit√© :", 0.01, 0.10, 0.05, 0.01, key="alpha_slider")

    jb_stat, jb_p_value = jarque_bera(rendements)
    shapiro_stat, shapiro_p_value = shapiro(rendements)
    ks_stat, ks_p_value = kstest(rendements, 'norm', args=(moyenne, ecart_type))
    ad_test = anderson(rendements, dist='norm')

    st.subheader("R√©sultats des tests statistiques :")
    results_df = pd.DataFrame({
        "Test": ["Jarque-Bera", "Shapiro-Wilk", "Kolmogorov-Smirnov", "Anderson-Darling"],
        "Statistique du test": [f"{jb_stat:.4f}", f"{shapiro_stat:.4f}", f"{ks_stat:.4f}", f"{ad_test.statistic:.4f}"],
        "P-value": [f"{jb_p_value:.4f}", f"{shapiro_p_value:.4f}", f"{ks_p_value:.4f}", "Voir ci-dessous"]
    })
    st.table(results_df)

    st.markdown("**Interpr√©tation pour Anderson-Darling :**")
    for i in range(len(ad_test.critical_values)):
        sl, cv = ad_test.significance_level[i], ad_test.critical_values[i]
        if ad_test.statistic < cv:
            st.write(f"Statistique ({ad_test.statistic:.3f}) < valeur critique ({cv:.3f}) au niveau de significativit√© de {sl}%. On ne rejette pas la normalit√©.")
        else:
            st.write(f"Statistique ({ad_test.statistic:.3f}) > valeur critique ({cv:.3f}) au niveau de significativit√© de {sl}%. On rejette la normalit√©.")

    normality_rejected = False
    if jb_p_value < alpha_test:
        st.warning(f"Test de Jarque-Bera : P-value ({jb_p_value:.4f}) < {alpha_test} ‚Üí On rejette l'hypoth√®se de normalit√©.")
        normality_rejected = True
    # ... (les autres tests de normalit√© suivent la m√™me logique)
    else:
        st.success(f"Test de Jarque-Bera : P-value ({jb_p_value:.4f}) >= {alpha_test} ‚Üí On ne rejette pas l'hypoth√®se de normalit√©.")

    if shapiro_p_value < alpha_test:
        st.warning(f"Test de Shapiro-Wilk : P-value ({shapiro_p_value:.4f}) < {alpha_test} ‚Üí On rejette l'hypoth√®se de normalit√©.")
        normality_rejected = True if not normality_rejected else True # Conserver True si d√©j√† rejet√©
    else:
        st.success(f"Test de Shapiro-Wilk : P-value ({shapiro_p_value:.4f}) >= {alpha_test} ‚Üí On ne rejette pas l'hypoth√®se de normalit√©.")

    if ks_p_value < alpha_test:
        st.warning(f"Test de Kolmogorov-Smirnov : P-value ({ks_p_value:.4f}) < {alpha_test} ‚Üí On rejette l'hypoth√®se de normalit√©.")
        normality_rejected = True if not normality_rejected else True
    else:
        st.success(f"Test de Kolmogorov-Smirnov : P-value ({ks_p_value:.4f}) >= {alpha_test} ‚Üí On ne rejette pas l'hypoth√®se de normalit√©.")


    # --- √âtape 4 : Visualisation ---
    st.header("√âtape 4 : Visualisation")

    st.subheader("Histogramme des rendements avec courbe de densit√© normale")
    fig, ax = plt.subplots(figsize=(10, 6))
    ax.hist(rendements, bins=50, density=True, alpha=0.6, color='g', label='Distribution des rendements')
    xmin, xmax_hist = ax.get_xlim() # Renomm√© pour √©viter conflit
    x_norm = np.linspace(xmin, xmax_hist, 100) # Renomm√© pour √©viter conflit
    p_norm = norm.pdf(x_norm, moyenne, ecart_type) # Renomm√© pour √©viter conflit
    ax.plot(x_norm, p_norm, 'k', linewidth=2, label='Densit√© normale th√©orique')
    ax.set_title("Histogramme des rendements et densit√© normale")
    ax.set_xlabel("Rendements")
    ax.set_ylabel("Densit√©")
    ax.legend()
    st.pyplot(fig)

    st.subheader("Q-Q Plot (Quantile-Quantile Plot)")
    fig_qq = plt.figure(figsize=(8, 6))
    sm.qqplot(rendements, line='s', ax=fig_qq.gca())
    plt.title("Q-Q Plot des rendements vs. Distribution Normale")
    st.pyplot(fig_qq)
    st.markdown("""
    Un Q-Q plot compare les quantiles de vos donn√©es aux quantiles d'une distribution normale th√©orique.
    Si les points suivent de pr√®s la ligne rouge, cela sugg√®re que les donn√©es sont normalement distribu√©es.
    Des d√©viations syst√©matiques de la ligne indiquent une non-normalit√©.
    """)

    # --- √âtape 5 : Choix de la m√©thode VaR ---
    st.header("√âtape 5 : Calcul de la VaR Gaussienne")

    if normality_rejected:
        st.error("""
        **Attention :** Les tests de normalit√© et/ou l'analyse descriptive sugg√®rent que
        la distribution des rendements **n'est probablement PAS normale**.
        La VaR gaussienne pourrait ne pas √™tre appropri√©e.
        Envisagez des m√©thodes alternatives.
        """)
    else:
        st.success("""
        Les tests ne rejettent pas fortement l'hypoth√®se de normalit√©.
        Vous pouvez proc√©der avec la VaR gaussienne, mais restez prudent.
        """)

    st.subheader("Calcul de la VaR Gaussienne")
    conf_level_percent = st.slider("Niveau de confiance pour la VaR (en %)", 90.0, 99.9, 95.0, 0.1, key="conf_level_slider")
    conf_level = conf_level_percent / 100.0
    horizon_var = st.number_input("Horizon de la VaR (en jours)", min_value=1, value=1, step=1, key="horizon_input")

    var_rendement_1_jour = moyenne + norm.ppf(1 - conf_level) * ecart_type
    var_percent_1_jour = -var_rendement_1_jour * 100

    var_rendement_h_jours = (moyenne * horizon_var) + (norm.ppf(1 - conf_level) * ecart_type * np.sqrt(horizon_var))
    var_percent_h_jours = -var_rendement_h_jours * 100

    st.subheader(f"R√©sultats de la VaR Gaussienne ({conf_level_percent}%) :")
    st.metric(f"VaR √† 1 jour (perte maximale en % du portefeuille)", f"{var_percent_1_jour:.4f}%")
    if horizon_var > 1:
        st.metric(f"VaR √† {horizon_var} jours (perte maximale en % du portefeuille)", f"{var_percent_h_jours:.4f}%")

    st.markdown(f"""
    Interpr√©tation : Il y a une probabilit√© de **{1-conf_level:.2%}** que la perte sur 1 jour d√©passe **{var_percent_1_jour:.4f}%**.
    """)
    if horizon_var > 1:
        st.markdown(f"""
        Il y a une probabilit√© de **{1-conf_level:.2%}** que la perte sur {horizon_var} jours d√©passe **{var_percent_h_jours:.4f}%**.
        """)

    st.markdown("""
    **Formule utilis√©e pour la VaR du rendement :**
    $$ VaR_{rendement, \\alpha} = \\mu + z_{\\alpha} \\cdot \\sigma $$
    Pour un horizon de $H$ jours :
    $$ VaR_{rendement, \\alpha, H} = \\mu \\cdot H + z_{\\alpha} \\cdot \\sigma \\cdot \\sqrt{H} $$
    """)

    # --- √âtape 6 : Backtesting (Placeholder) ---
    st.header("√âtape 6 : Backtesting (non impl√©ment√©)")
    st.info("Le backtesting est crucial mais non impl√©ment√© ici.")

elif uploaded_file is not None and not st.session_state.columns_validated:
    st.info("Veuillez valider la s√©lection des colonnes pour continuer l'analyse.")
elif uploaded_file is None:
    st.info("Veuillez charger un fichier CSV pour commencer l'analyse.")


st.sidebar.header("√Ä propos")
st.sidebar.info("""
Cette application Streamlit impl√©mente le plan d'action pour calculer une VaR Gaussienne,
avec s√©lection manuelle des colonnes Date et Cl√¥ture.
""")
st.sidebar.markdown("---")
st.sidebar.markdown("D√©velopp√© avec Python et Streamlit.")
